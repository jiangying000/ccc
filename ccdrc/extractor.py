#!/usr/bin/env python3
"""
Claude Context Smart Extract Tool
æ™ºèƒ½æå–Claudeå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä¼˜åŒ–tokenä½¿ç”¨
"""

import json
import os
import sys
import re
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import hashlib
import time
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing

# å¯¼å…¥å·¥å…·è°ƒç”¨å‡€åŒ–å™¨
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
try:
    from tool_call_sanitizer import sanitize_tool_call, sanitize_tool_result
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæä¾›ç®€å•çš„åå¤‡æ–¹æ¡ˆ
    def sanitize_tool_call(tool_name, tool_input):
        return f"[Tool: {tool_name}]"
    def sanitize_tool_result(result_content, max_length=100):
        return "[Tool Result]"

# Tokenè®¡ç®—æ–¹å¼
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False

class ClaudeContextExtractor:
    """Claudeå¯¹è¯ä¸Šä¸‹æ–‡æ™ºèƒ½æå–å™¨"""
    
    def __init__(self, max_tokens: int = 100000, verbose: bool = False):
        self.max_tokens = max_tokens
        self.encoder = None
        self.verbose = verbose
        
        if TIKTOKEN_AVAILABLE:
            try:
                # å°è¯•æœ€æ–°çš„o200k_baseï¼ˆGPT-4oå’ŒClaude 3.5ä½¿ç”¨ï¼‰
                self.encoder = tiktoken.get_encoding("o200k_base")
                self.encoding_name = "o200k_base"
                self.vocab_size = self.encoder.n_vocab
            except Exception:
                try:
                    # é€€å›åˆ°cl100k_base
                    self.encoder = tiktoken.get_encoding("cl100k_base")
                    self.encoding_name = "cl100k_base"
                    self.vocab_size = self.encoder.n_vocab
                except Exception:
                    self.encoding_name = "estimation"
                    self.vocab_size = 0
        else:
            self.encoding_name = "estimation"
            self.vocab_size = 0
    
    def count_tokens(self, text: str) -> int:
        """ç²¾ç¡®è®¡ç®—tokenæ•°é‡ï¼ˆä½¿ç”¨tiktokenï¼‰"""
        if self.encoder:
            try:
                return len(self.encoder.encode(text))
            except:
                # å¦‚æœç¼–ç å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—
                pass
        
        # æ”¹è¿›çš„ä¼°ç®—æ¨¡å¼
        # Claudeå’ŒGPTçš„tokenizerç±»ä¼¼ï¼Œä½†æœ‰åŒºåˆ«
        # åŸºæœ¬è§„åˆ™ï¼š
        # - è‹±æ–‡ï¼šå¹³å‡3-4ä¸ªå­—ç¬¦ = 1 tokenï¼ˆåŒ…æ‹¬ç©ºæ ¼ï¼‰
        # - ä¸­æ–‡ï¼š1ä¸ªå­—ç¬¦ â‰ˆ 1.5-2 tokens
        # - æ··åˆå†…å®¹éœ€è¦ç»¼åˆè€ƒè™‘
        
        total_chars = len(text)
        
        # è®¡ç®—ä¸­æ–‡å­—ç¬¦
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        non_chinese_chars = total_chars - chinese_chars
        
        # åŸºç¡€ä¼°ç®—
        if chinese_chars > non_chinese_chars:
            # ä¸­æ–‡ä¸ºä¸»çš„å†…å®¹
            estimated = (chinese_chars * 1.8) + (non_chinese_chars / 3.5)
        else:
            # è‹±æ–‡ä¸ºä¸»çš„å†…å®¹
            # å¯¹äºè‹±æ–‡ï¼Œæ›´å‡†ç¡®çš„ä¼°ç®—æ˜¯æ€»å­—ç¬¦æ•°é™¤ä»¥3.5
            estimated = non_chinese_chars / 3.5 + (chinese_chars * 1.8)
        
        # ç‰¹æ®Šæƒ…å†µè°ƒæ•´
        if '```' in text:
            # ä»£ç å—tokenæ›´å¤š
            estimated *= 1.2
        
        if text.count('\n') > len(text) / 50:
            # å¾ˆå¤šæ¢è¡Œçš„å†…å®¹ï¼ˆå¦‚æ—¥å¿—ã€åˆ—è¡¨ï¼‰tokenæ›´å¤š
            estimated *= 1.1
        
        # ç¡®ä¿ä¸ä¼šå¤ªç¦»è°±
        # æœ€å°‘ï¼šå­—ç¬¦æ•°/10ï¼ˆéå¸¸å¯†é›†çš„å†…å®¹ï¼‰
        # æœ€å¤šï¼šå­—ç¬¦æ•°/2ï¼ˆéå¸¸ç¨€ç–çš„å†…å®¹ï¼‰
        estimated = max(total_chars / 10, min(estimated, total_chars / 2))
        
        return int(estimated)
    
    def find_claude_sessions(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Claudeä¼šè¯æ–‡ä»¶"""
        claude_dir = Path.home() / '.claude' / 'projects'
        
        if not claude_dir.exists():
            return []
        
        # æŸ¥æ‰¾æ‰€æœ‰.jsonlæ–‡ä»¶
        sessions = []
        for project_dir in claude_dir.iterdir():
            if project_dir.is_dir():
                for jsonl_file in project_dir.glob('*.jsonl'):
                    # åªæŸ¥æ‰¾UUIDæ ¼å¼çš„ä¼šè¯æ–‡ä»¶
                    if re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\.jsonl$', 
                               jsonl_file.name):
                        # è¿‡æ»¤æ‰å¤ªå°çš„æ–‡ä»¶ï¼ˆå°äº1KBé€šå¸¸æ˜¯ç©ºä¼šè¯ï¼‰
                        if jsonl_file.stat().st_size > 1024:  # å¤§äº1KB
                            sessions.append(jsonl_file)
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        sessions.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return sessions
    
    def extract_meaningful_messages(self, messages: List[Dict], count: int = 5) -> List[str]:
        """æå–æœ‰æ„ä¹‰çš„æ¶ˆæ¯å†…å®¹ï¼Œä¼˜å…ˆæ˜¾ç¤ºç”¨æˆ·å¯¹è¯è€Œéå·¥å…·è°ƒç”¨"""
        meaningful = []
        
        # ä¼˜å…ˆæå–ç”¨æˆ·æ¶ˆæ¯å’ŒClaudeçš„æ–‡æœ¬å›å¤
        user_messages = []
        assistant_messages = []
        
        for msg in messages:
            # åˆ¤æ–­æ¶ˆæ¯è§’è‰²
            role = None
            if 'message' in msg and isinstance(msg['message'], dict):
                role = msg['message'].get('role')
            elif 'type' in msg:
                if msg['type'] == 'human':
                    role = 'user'
                elif msg['type'] == 'assistant':
                    role = 'assistant'
            
            content = self._get_message_content(msg)
            if not content:
                continue
                
            # è·³è¿‡å·¥å…·è°ƒç”¨å’Œç»“æœ
            if content.startswith('[Tool:') or content.startswith('[Tool Result]'):
                continue
                
            # è·³è¿‡æ€è€ƒå†…å®¹ï¼ˆå¤ªé•¿ï¼‰
            if content.startswith('[Thinking]'):
                continue
                
            # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯å’Œæ¨¡æ¿
            if any(p in content for p in ['# æå–çš„å¯¹è¯ä¸Šä¸‹æ–‡', '# ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡', 
                                          'This session is being continued', '_å…±', '---',
                                          '[Request interrupted', 'No response requested']):
                continue
            
            # æ¸…ç†å†…å®¹
            lines = content.split('\n')
            clean_lines = []
            for line in lines:
                line = line.strip()
                if line and len(line) > 10 and not line.startswith('#') and not line.startswith('_'):
                    # ç§»é™¤markdownæ ¼å¼
                    if line.startswith('**') and line.endswith('**'):
                        line = line[2:-2]
                    clean_lines.append(line)
            
            if clean_lines:
                clean_content = ' '.join(clean_lines[:3])[:300]  # å–å‰3è¡Œï¼Œæœ€å¤š300å­—ç¬¦
                if role == 'user' or role == 'human':
                    user_messages.append(('ğŸ‘¤ ' + clean_content, len(user_messages)))
                elif role == 'assistant':
                    assistant_messages.append(('ğŸ¤– ' + clean_content, len(assistant_messages)))
                else:
                    # æœªçŸ¥è§’è‰²ï¼Œå°è¯•ä»å†…å®¹åˆ¤æ–­
                    if any(marker in content for marker in ['ç”¨æˆ·:', 'User:', 'Human:']):
                        user_messages.append(('ğŸ‘¤ ' + clean_content, len(user_messages)))
                    elif any(marker in content for marker in ['Claude:', 'Assistant:', 'åŠ©æ‰‹:']):
                        assistant_messages.append(('ğŸ¤– ' + clean_content, len(assistant_messages)))
        
        # äº¤æ›¿æ·»åŠ ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯ï¼Œä¿æŒå¯¹è¯æµ
        added_user = 0
        added_assistant = 0
        
        while len(meaningful) < count and (added_user < len(user_messages) or added_assistant < len(assistant_messages)):
            # ä¼˜å…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            if added_user < len(user_messages):
                meaningful.append(user_messages[added_user][0])
                added_user += 1
            
            # ç„¶åæ·»åŠ åŠ©æ‰‹å›å¤
            if added_assistant < len(assistant_messages) and len(meaningful) < count:
                meaningful.append(assistant_messages[added_assistant][0])
                added_assistant += 1
        
        # å¦‚æœè¿˜æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„æ¶ˆæ¯ï¼Œä½¿ç”¨æ—§çš„é€»è¾‘ä½œä¸ºåå¤‡
        if len(meaningful) < 2:
            skip_patterns = [
                '# æå–çš„å¯¹è¯ä¸Šä¸‹æ–‡', '# ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡', 
                'This session is being continued', '_å…±', '---',
                '[Request interrupted', 'No response requested',
                '[Tool Result] File created successfully',
                '[Tool Result] The file',
                '[Tool Result] Todos have been modified'
            ]
            
            # å…³é”®è¯æƒé‡ï¼ˆå¸®åŠ©è¯†åˆ«é‡è¦å†…å®¹ï¼‰
            keywords = {
                'bug': 5, 'error': 5, 'é”™è¯¯': 5, 'fix': 4, 'ä¿®å¤': 4,
                'implement': 4, 'å®ç°': 4, 'create': 4, 'åˆ›å»º': 4,
                'database': 3, 'æ•°æ®åº“': 3, 'api': 3, 'API': 3,
                'function': 3, 'å‡½æ•°': 3, 'class': 3, 'ç±»': 3,
                'test': 3, 'æµ‹è¯•': 3, 'deploy': 3, 'éƒ¨ç½²': 3,
                'webhook': 4, 'line': 4, 'LINE': 4, 'telegram': 4,
                'docker': 3, 'kubernetes': 3, 'aws': 3, 'azure': 3,
                'react': 3, 'vue': 3, 'python': 3, 'javascript': 3,
                'install': 3, 'å®‰è£…': 3, 'setup': 3, 'é…ç½®': 3,
                'optimize': 3, 'ä¼˜åŒ–': 3, 'performance': 3, 'æ€§èƒ½': 3
            }
            
            scored_messages = []
            
            for msg in messages:
                content = self._get_message_content(msg)
                if not content:
                    continue
                
                # è·³è¿‡æ— æ„ä¹‰å†…å®¹
                if any(pattern in content for pattern in skip_patterns):
                    continue
            
                # æå–å¹¶è¯„åˆ†æ¯è¡Œ
                lines = content.split('\n')
                for line in lines:
                    line = line.strip()
                
                # è·³è¿‡å¤ªçŸ­æˆ–ç‰¹æ®Šæ ‡è®°
                if not line or len(line) < 10 or line.startswith('#') or \
                   line.startswith('_') or line.startswith('**') or line == '---':
                    continue
                
                # æ¸…ç†å¯¹è¯æ ‡è®°
                if any(marker in line for marker in ['ç”¨æˆ·:', 'Claude:', 'åŠ©æ‰‹:', 'User:', 'Human:', 'Assistant:']):
                    if ':' in line:
                        parts = line.split(':', 1)
                        if len(parts) > 1:
                            line = parts[1].strip()
                
                # è·³è¿‡å·¥å…·è°ƒç”¨ - è¿™äº›å†…å®¹å¯¹ç”¨æˆ·æ— æ„ä¹‰
                if line.startswith('[Tool:') or line.startswith('[Tool Result]') or line.startswith('[Thinking]'):
                    continue
                
                if not line or len(line) < 10:
                    continue
                
                # è®¡ç®—å¾—åˆ†ï¼ˆåŒ…å«çš„å…³é”®è¯è¶Šå¤šåˆ†æ•°è¶Šé«˜ï¼‰
                score = 0
                lower_line = line.lower()
                for keyword, weight in keywords.items():
                    if keyword.lower() in lower_line:
                        score += weight
                
                # é¢å¤–åŠ åˆ†é¡¹
                if '?' in line or 'ï¼Ÿ' in line:  # é—®é¢˜
                    score += 2
                if any(c in line for c in ['()', '[]', '{}', '->', '=>']):  # ä»£ç ç›¸å…³
                    score += 3
                if re.search(r'\.(py|js|ts|jsx|tsx|java|go|rs|cpp|c|sh|yml|yaml|json)', line):  # æ–‡ä»¶å
                    score += 4
                if re.search(r'[0-9]+\.[0-9]+', line):  # ç‰ˆæœ¬å·
                    score += 2
                
                # ä¿å­˜è¯„åˆ†åçš„æ¶ˆæ¯ï¼ˆä¿ç•™å®Œæ•´å†…å®¹ï¼‰
                preview = line[:300] if len(line) > 300 else line
                scored_messages.append((score, preview, line))
        
            # æŒ‰å¾—åˆ†æ’åºï¼Œå–æœ€æœ‰ç‰¹å¾çš„
            scored_messages.sort(key=lambda x: x[0], reverse=True)
            
            # å–å‰Nä¸ªæœ€æœ‰ç‰¹å¾çš„æ¶ˆæ¯ï¼Œé¿å…é‡å¤
            seen = set()
            seen_prefixes = set()  # ç”¨äºæ£€æŸ¥ç›¸ä¼¼å†…å®¹
            for score, preview, full in scored_messages:
                # é¿å…é‡å¤ï¼ˆç›¸ä¼¼åº¦æ£€æŸ¥ï¼‰
                preview_key = preview[:30].lower()
                preview_prefix = preview[:20].lower()
                
                # è·³è¿‡å¤ªç›¸ä¼¼çš„å†…å®¹
                if preview_key not in seen and preview_prefix not in seen_prefixes:
                    # é¢å¤–æ£€æŸ¥ï¼šé¿å…é‡å¤çš„æ–‡ä»¶åæˆ–å‘½ä»¤
                    is_duplicate = False
                    for existing in meaningful:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åŒæ–‡ä»¶çš„ä¸åŒæ“ä½œ
                        if ('æ–‡ä»¶:' in preview and 'æ–‡ä»¶:' in existing and 
                            preview.split('æ–‡ä»¶:')[1][:10] == existing.split('æ–‡ä»¶:')[1][:10]):
                            is_duplicate = True
                            break
                        # æ£€æŸ¥ç›¸ä¼¼åº¦
                        if len(set(preview.split()) & set(existing.split())) > len(preview.split()) * 0.6:
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        meaningful.append(preview)
                        seen.add(preview_key)
                        seen_prefixes.add(preview_prefix)
                        if len(meaningful) >= count:
                            break
        
            # å¦‚æœæ²¡æ‰¾åˆ°æœ‰ç‰¹å¾çš„ï¼Œè‡³å°‘è¿”å›ä¸€äº›å†…å®¹
            if len(meaningful) < 2:
                for msg in messages[:5]:
                    content = self._get_message_content(msg)
                    if content:
                        lines = content.split('\n')
                        for line in lines:
                            line = line.strip()
                            if line and len(line) > 20 and not any(p in line for p in skip_patterns):
                                meaningful.append(line[:300])
                                break
                    if len(meaningful) >= count:
                        break
        
        return meaningful[:count]
    
    def identify_session_topics(self, messages: List[Dict], summaries: List[str] = None, max_topics: int = 3) -> List[str]:
        """è¯†åˆ«ä¼šè¯çš„ä¸»è¦è¯é¢˜"""
        # è¯é¢˜å…³é”®è¯å’Œåˆ†ç±»
        topic_keywords = {
            'CCDRCå·¥å…·': ['ccdrc', 'token', 'ä¼šè¯', 'claude', 'context', 'extract', 'æå–'],
            'åŒ…ç®¡ç†': ['pip', 'pipx', 'uvx', 'uv', 'install', 'package', 'å®‰è£…', 'åŒ…'],
            'Gitæ“ä½œ': ['git', 'commit', 'push', 'pull', 'branch', 'merge', 'checkout'],
            'Docker': ['docker', 'container', 'dockerfile', 'compose', 'kubernetes', 'k8s'],
            'æµ‹è¯•': ['test', 'pytest', 'unittest', 'æµ‹è¯•', 'testing', 'spec'],
            'æ•°æ®åº“': ['database', 'sql', 'postgres', 'mysql', 'mongodb', 'æ•°æ®åº“'],
            'APIå¼€å‘': ['api', 'endpoint', 'rest', 'graphql', 'webhook', 'æ¥å£'],
            'å‰ç«¯å¼€å‘': ['react', 'vue', 'angular', 'javascript', 'typescript', 'css', 'html'],
            'Pythonå¼€å‘': ['python', 'django', 'flask', 'fastapi', 'poetry', 'venv'],
            'é…ç½®æ–‡ä»¶': ['config', 'yaml', 'json', 'toml', 'é…ç½®', 'settings', 'è®¾ç½®', 'codex'],
            'é”™è¯¯è°ƒè¯•': ['error', 'bug', 'fix', 'debug', 'é”™è¯¯', 'ä¿®å¤', 'è°ƒè¯•', 'issue'],
            'æ–‡æ¡£': ['readme', 'docs', 'documentation', 'æ–‡æ¡£', 'markdown', 'md'],
            'éƒ¨ç½²': ['deploy', 'production', 'server', 'éƒ¨ç½²', 'å‘å¸ƒ', 'release'],
            'AI/LLM': ['claude', 'gpt', 'llm', 'ai', 'model', 'æ¨¡å‹', 'prompt', 'opus'],
            'æ¶ˆæ¯å¹³å°': ['line', 'telegram', 'whatsapp', 'discord', 'slack', 'webhook'],
        }
        
        # è®¡ç®—æ¯ä¸ªè¯é¢˜çš„å¾—åˆ†
        topic_scores = {}
        
        # å…ˆåˆ†ææ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œæƒé‡æ›´é«˜ï¼‰
        if summaries:
            for summary in summaries:
                summary_lower = summary.lower()
                for topic, keywords in topic_keywords.items():
                    for keyword in keywords:
                        if keyword.lower() in summary_lower:
                            # æ‘˜è¦ä¸­çš„å…³é”®è¯æƒé‡æ›´é«˜
                            topic_scores[topic] = topic_scores.get(topic, 0) + 3
        
        # åˆ†ææ¶ˆæ¯å†…å®¹
        for msg in messages[:50]:  # åªåˆ†æå‰50æ¡æ¶ˆæ¯
            content = self._get_message_content(msg)
            if content:
                content_lower = content.lower()
                for topic, keywords in topic_keywords.items():
                    for keyword in keywords:
                        if keyword.lower() in content_lower:
                            topic_scores[topic] = topic_scores.get(topic, 0) + 1
        
        # æŒ‰å¾—åˆ†æ’åºï¼Œè¿”å›å‰Nä¸ªè¯é¢˜
        sorted_topics = sorted(topic_scores.items(), key=lambda x: x[1], reverse=True)
        topics = [topic for topic, score in sorted_topics[:max_topics] if score > 1]
        
        return topics
    
    def get_session_info(self, session_path: Path) -> Dict:
        """è·å–ä¼šè¯çš„è¯¦ç»†ä¿¡æ¯"""
        info = {
            'path': session_path,
            'name': session_path.name,
            'size': session_path.stat().st_size,
            'mtime': session_path.stat().st_mtime,
            'message_count': 0,
            'meaningful_messages': [],  # æœ‰æ„ä¹‰çš„æ¶ˆæ¯åˆ—è¡¨
            'last_messages': [],  # æœ€åå‡ æ¡æ¶ˆæ¯
            'tokens': 0,
            'topics': [],  # ä¼šè¯ä¸»é¢˜
            'summaries': [],  # Claudeç”Ÿæˆçš„æ‘˜è¦
            'git_branch': None,  # Gitåˆ†æ”¯
            'duration': None,  # ä¼šè¯æŒç»­æ—¶é—´
            'project_dir': session_path.parent.name
        }
        
        try:
            messages = self.parse_session(session_path)
            info['message_count'] = len(messages)
            
            # æå–æ‘˜è¦å’Œå…ƒä¿¡æ¯
            first_timestamp = None
            last_timestamp = None
            summaries = []
            
            for msg in messages:
                # æå–æ‘˜è¦
                if msg.get('type') == 'summary':
                    summary_text = msg.get('summary', '')
                    if summary_text and summary_text not in summaries:
                        summaries.append(summary_text)
                
                # æå–Gitåˆ†æ”¯ï¼ˆå–ç¬¬ä¸€ä¸ªéç©ºçš„ï¼‰
                if not info['git_branch'] and msg.get('gitBranch'):
                    info['git_branch'] = msg['gitBranch']
                
                # æå–æ—¶é—´æˆ³
                if msg.get('timestamp'):
                    if not first_timestamp:
                        first_timestamp = msg['timestamp']
                    last_timestamp = msg['timestamp']
            
            info['summaries'] = summaries[:3]  # æœ€å¤šä¿ç•™3ä¸ªæ‘˜è¦
            
            # è®¡ç®—ä¼šè¯æŒç»­æ—¶é—´
            if first_timestamp and last_timestamp:
                try:
                    from datetime import datetime
                    start = datetime.fromisoformat(first_timestamp.replace('Z', '+00:00'))
                    end = datetime.fromisoformat(last_timestamp.replace('Z', '+00:00'))
                    duration = end - start
                    if duration.days > 0:
                        info['duration'] = f"{duration.days}å¤©"
                    elif duration.seconds > 3600:
                        info['duration'] = f"{duration.seconds // 3600}å°æ—¶"
                    elif duration.seconds > 60:
                        info['duration'] = f"{duration.seconds // 60}åˆ†é’Ÿ"
                    else:
                        info['duration'] = "åˆšåˆš"
                except:
                    pass
            
            # è¯†åˆ«ä¼šè¯ä¸»é¢˜ï¼ˆç»“åˆæ‘˜è¦ä¿¡æ¯ï¼‰
            info['topics'] = self.identify_session_topics(messages, summaries)
            
            # æå–æœ‰æ„ä¹‰çš„æ¶ˆæ¯ï¼ˆå‰é¢çš„ï¼‰- å¢åŠ åˆ°5æ¡ä»¥æä¾›æ›´å¤šåŒºåˆ†åº¦
            info['meaningful_messages'] = self.extract_meaningful_messages(messages[:30], count=5)
            
            # æå–æœ€åå‡ æ¡æœ‰æ„ä¹‰çš„æ¶ˆæ¯ï¼ˆæ›´å®¹æ˜“è®°ä½ï¼‰- å¢åŠ åˆ°5æ¡
            if len(messages) > 10:
                info['last_messages'] = self.extract_meaningful_messages(messages[-30:], count=5)
            
            # å‡†ç¡®è®¡ç®—ï¼šåªç®—å†…å®¹ï¼Œä¸ç®—JSONç»“æ„
            total_tokens = 0
            
            if self.verbose:
                print(f"  å¼€å§‹è®¡ç®—tokensï¼Œæ¶ˆæ¯æ•°: {len(messages)}", file=sys.stderr)
            
            if self.encoder:
                # æ”¶é›†æ‰€æœ‰å®é™…å†…å®¹æ–‡æœ¬
                all_texts = []
                
                for msg in messages:
                    try:
                        # æå–ä¸åŒç±»å‹çš„å†…å®¹
                        msg_type = msg.get('type', '')
                        
                        # 1. å¤„ç†messageå­—æ®µä¸­çš„å†…å®¹
                        if 'message' in msg:
                            message = msg['message']
                            
                            # æå–content
                            if 'content' in message:
                                content = message['content']
                                if isinstance(content, list):
                                    for item in content:
                                        if isinstance(item, dict):
                                            # æ–‡æœ¬å†…å®¹
                                            if 'text' in item:
                                                all_texts.append(item['text'])
                                            # thinkingå†…å®¹ï¼ˆé‡è¦ï¼ï¼‰
                                            if 'thinking' in item:
                                                all_texts.append(item['thinking'])
                                            # signatureç­¾åï¼ˆå…¨éƒ¨è®¡å…¥ï¼‰
                                            if 'signature' in item:
                                                all_texts.append(item['signature'])
                                            # toolè¾“å…¥å‚æ•°
                                            if 'input' in item and isinstance(item['input'], dict):
                                                for value in item['input'].values():
                                                    if isinstance(value, str):
                                                        all_texts.append(value)
                                            # åµŒå¥—çš„content
                                            if 'content' in item and isinstance(item['content'], str):
                                                all_texts.append(item['content'])
                                elif isinstance(content, str):
                                    all_texts.append(content)
                        
                        # 2. å¤„ç†toolUseResultå­—æ®µï¼ˆå·¥å…·æ‰§è¡Œç»“æœï¼‰
                        if 'toolUseResult' in msg:
                            result = msg['toolUseResult']
                            # stdout/stderrè¾“å‡º
                            for key in ['stdout', 'stderr', 'output', 'error', 'result']:
                                if key in result and isinstance(result[key], str):
                                    all_texts.append(result[key])
                            # resultsæ•°ç»„
                            if 'results' in result and isinstance(result['results'], list):
                                for r in result['results']:
                                    if isinstance(r, str):
                                        all_texts.append(r)
                            # fileå†…å®¹
                            if 'file' in result and isinstance(result['file'], dict):
                                if 'content' in result['file']:
                                    all_texts.append(result['file']['content'])
                        
                        # 3. å¤„ç†summaryå­—æ®µ
                        if 'summary' in msg:
                            all_texts.append(msg['summary'])
                            
                    except Exception as e:
                        if self.verbose:
                            print(f"  âš  å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)[:50]}", file=sys.stderr)
                        continue
                
                # è®¡ç®—æ‰€æœ‰æ–‡æœ¬çš„tokens
                if all_texts:
                    combined_text = ' '.join(all_texts)
                    tokens = self.encoder.encode(combined_text)
                    total_tokens = len(tokens)
                    
            else:
                # æ²¡æœ‰tokenizerï¼Œç”¨ç®€å•ä¼°ç®—
                for msg in messages:
                    total_tokens += len(str(msg)) // 10
            
            info['tokens'] = total_tokens
            
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ä¸å´©æºƒ
            print(f"  âš   è®¡ç®—ä¼šè¯ä¿¡æ¯æ—¶å‡ºé”™: {str(e)[:50]}", file=sys.stderr)
        
        return info
    
    def parse_session(self, session_path: Path) -> List[Dict]:
        """è§£æä¼šè¯æ–‡ä»¶"""
        messages = []
        
        try:
            with open(session_path, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        msg = json.loads(line.strip())
                        messages.append(msg)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            print(f"âš   è¯»å–ä¼šè¯å¤±è´¥: {e}", file=sys.stderr)
        
        # æ¸…ç†å·¥å…·è°ƒç”¨JSONæ±¡æŸ“ï¼ˆä¿ç•™æ­£å¸¸JSONï¼‰
        if messages and self.verbose:
            print(f"  ğŸ§¹ æ¸…ç†å·¥å…·è°ƒç”¨JSONæ±¡æŸ“...", file=sys.stderr)
        messages = self._clean_tool_call_pollution(messages)
        
        return messages
    
    def _clean_tool_call_pollution(self, messages: List[Dict]) -> List[Dict]:
        """æ¸…ç†å·¥å…·è°ƒç”¨JSONæ±¡æŸ“ï¼Œä¿ç•™æ­£å¸¸çš„JSONæ•°æ®"""
        import re
        import copy
        
        def clean_tool_json(text: str) -> str:
            """åªæ¸…ç†å·¥å…·è°ƒç”¨JSONï¼Œä¿ç•™å…¶ä»–JSON"""
            if not text or '[Tool:' not in text:
                return text
            
            # æ¸…ç†æ¨¡å¼ï¼š[Tool: Name] {json with specific keys}
            # åªæ¸…ç†åŒ…å«å·¥å…·è°ƒç”¨ç‰¹å¾é”®çš„JSON
            patterns = [
                # Writeå·¥å…·
                (r'\[Tool:\s*Write\]\s*\{[^}]*"file_path"[^}]*"content"[^}]*\}', '[Created file]'),
                # Editå·¥å…·
                (r'\[Tool:\s*Edit\]\s*\{[^}]*"file_path"[^}]*"old_string"[^}]*\}', '[Edited file]'),
                # Bashå·¥å…·
                (r'\[Tool:\s*Bash\]\s*\{[^}]*"command"[^}]*\}', '[Executed command]'),
                # Grepå·¥å…·
                (r'\[Tool:\s*Grep\]\s*\{[^}]*"pattern"[^}]*\}', '[Searched]'),
                # é€šç”¨å·¥å…·JSONï¼ˆåŒ…å«inputé”®ï¼‰
                (r'\[Tool:\s*(\w+)\]\s*\{[^}]*"input"[^}]*\}', r'[Used tool: \1]'),
                # å…¶ä»–æ˜æ˜¾çš„å·¥å…·è°ƒç”¨
                (r'\[Tool:\s*(\w+)\]\s*\{"[^"]+"\s*:\s*"[^"]+"\}', r'[Used tool: \1]'),
            ]
            
            cleaned = text
            for pattern, replacement in patterns:
                cleaned = re.sub(pattern, replacement, cleaned, flags=re.DOTALL)
            
            return cleaned
        
        cleaned_messages = []
        for msg in messages:
            msg_copy = copy.deepcopy(msg)
            
            # é€’å½’æ¸…ç†æ¶ˆæ¯å†…å®¹
            def clean_recursive(obj):
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        if key == 'text' and isinstance(value, str):
                            obj[key] = clean_tool_json(value)
                        elif key == 'content':
                            if isinstance(value, str):
                                obj[key] = clean_tool_json(value)
                            elif isinstance(value, list):
                                for item in value:
                                    if isinstance(item, dict) and item.get('type') == 'text':
                                        if 'text' in item:
                                            item['text'] = clean_tool_json(item['text'])
                                    clean_recursive(item)
                        elif isinstance(value, (dict, list)):
                            clean_recursive(value)
                elif isinstance(obj, list):
                    for item in obj:
                        clean_recursive(item)
            
            clean_recursive(msg_copy)
            cleaned_messages.append(msg_copy)
        
        return cleaned_messages
    
    def _binary_search_truncate(self, content: str, target_tokens: int) -> str:
        """ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ç²¾ç¡®åˆ‡å‰²å†…å®¹åˆ°ç›®æ ‡tokenæ•°
        
        Args:
            content: è¦åˆ‡å‰²çš„å†…å®¹
            target_tokens: ç›®æ ‡tokenæ•°
        
        Returns:
            åˆ‡å‰²åçš„å†…å®¹ï¼Œç¡®ä¿tokenæ•°ä¸è¶…è¿‡target_tokens
        """
        if not content:
            return ""
        
        # é¦–å…ˆæ£€æŸ¥å®Œæ•´å†…å®¹
        full_tokens = self.count_tokens(content)
        if full_tokens <= target_tokens:
            return content
        
        # äºŒåˆ†æŸ¥æ‰¾æœ€ä½³åˆ‡å‰²ç‚¹
        left, right = 0, len(content)
        best_pos = 0
        best_tokens = 0
        
        # æœ€å¤šè¿­ä»£20æ¬¡é¿å…æ— é™å¾ªç¯
        for _ in range(20):
            if left >= right - 1:
                break
                
            mid = (left + right) // 2
            truncated = content[:mid]
            tokens = self.count_tokens(truncated)
            
            if tokens <= target_tokens:
                # è®°å½•æœ€ä½³ä½ç½®
                if tokens > best_tokens:
                    best_pos = mid
                    best_tokens = tokens
                left = mid
            else:
                right = mid
        
        # è¿”å›æœ€ä½³åˆ‡å‰²
        return content[:best_pos]
    
    def extract_key_messages(self, messages: List[Dict]) -> Tuple[List[Dict], Dict]:
        """æ™ºèƒ½æå–å…³é”®æ¶ˆæ¯ - å‰25k + å75kç­–ç•¥"""
        if not messages:
            return [], {}
        
        stats = {
            'total_messages': len(messages),
            'extracted_messages': 0,
            'total_tokens': 0,
            'extracted_tokens': 0,
            'compression_ratio': 0
        }
        
        # è®¡ç®—æ‰€æœ‰æ¶ˆæ¯çš„token
        message_tokens = []
        for msg in messages:
            content = self._get_message_content(msg)
            if content:
                tokens = self.count_tokens(content)
                message_tokens.append((msg, content, tokens))
                stats['total_tokens'] += tokens
            else:
                message_tokens.append((msg, '', 0))
        
        # ç­–ç•¥ï¼šå‰25k + å75k = 100k tokens
        # ä½¿ç”¨ç²¾ç¡®åˆ‡å‰²ç®—æ³•ç¡®ä¿è¾¾åˆ°ç›®æ ‡
        FRONT_TOKENS = 25000
        BACK_TOKENS = 75000
        
        front_messages = []
        back_messages = []
        
        # 1. æå–å‰25k tokensçš„æ¶ˆæ¯ï¼ˆç²¾ç¡®åˆ‡å‰²ï¼‰
        front_token_count = 0
        for i, (msg, content, tokens) in enumerate(message_tokens):
            if tokens == 0:
                continue
                
            if front_token_count + tokens <= FRONT_TOKENS:
                # å®Œæ•´æ·»åŠ è¿™æ¡æ¶ˆæ¯
                front_messages.append(msg)
                front_token_count += tokens
            else:
                # éœ€è¦åˆ‡å‰²è¿™æ¡æ¶ˆæ¯
                remaining_tokens = FRONT_TOKENS - front_token_count
                if remaining_tokens > 100:  # å¦‚æœå‰©ä½™ç©ºé—´è¶³å¤Ÿï¼ˆ>100 tokensï¼‰ï¼Œè¿›è¡Œåˆ‡å‰²
                    # ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ç²¾ç¡®åˆ‡å‰²å†…å®¹
                    truncated_content = self._binary_search_truncate(content, remaining_tokens)
                    
                    # åˆ›å»ºåˆ‡å‰²åçš„æ¶ˆæ¯
                    truncated_msg = msg.copy()
                    
                    # æ›´æ–°æ¶ˆæ¯å†…å®¹
                    if 'message' in truncated_msg and 'content' in truncated_msg['message']:
                        if isinstance(truncated_msg['message']['content'], list):
                            for item in truncated_msg['message']['content']:
                                if item.get('type') == 'text':
                                    item['text'] = truncated_content + "\n\n[...å†…å®¹å·²æˆªæ–­...]\n"
                                    break
                        else:
                            truncated_msg['message']['content'] = truncated_content + "\n\n[...å†…å®¹å·²æˆªæ–­...]\n"
                    
                    front_messages.append(truncated_msg)
                    # è®¡ç®—å®é™…æ·»åŠ çš„tokensï¼ˆè€Œä¸æ˜¯å‡è®¾å€¼ï¼‰
                    actual_truncated_tokens = self.count_tokens(truncated_content)
                    front_token_count += actual_truncated_tokens
                break  # è¾¾åˆ°ç›®æ ‡ï¼Œåœæ­¢
        
        # 2. æå–å75k tokensçš„æ¶ˆæ¯ï¼ˆä»åå¾€å‰ï¼Œç²¾ç¡®åˆ‡å‰²ï¼‰
        back_token_count = 0
        temp_back = []
        front_msg_set = set(id(m) for m in front_messages)  # ç”¨idé¿å…æ¯”è¾ƒæ•´ä¸ªdict
        
        for i, (msg, content, tokens) in enumerate(reversed(message_tokens)):
            if tokens == 0:
                continue
            # è·³è¿‡å·²ç»åœ¨front_messagesä¸­çš„æ¶ˆæ¯
            if id(msg) in front_msg_set:
                continue
                
            if back_token_count + tokens <= BACK_TOKENS:
                # å®Œæ•´æ·»åŠ è¿™æ¡æ¶ˆæ¯
                temp_back.append(msg)
                back_token_count += tokens
            else:
                # éœ€è¦åˆ‡å‰²è¿™æ¡æ¶ˆæ¯ï¼ˆä»åé¢åˆ‡ï¼‰
                remaining_tokens = BACK_TOKENS - back_token_count
                if remaining_tokens > 100:  # å¦‚æœå‰©ä½™ç©ºé—´è¶³å¤Ÿï¼ˆ>100 tokensï¼‰ï¼Œè¿›è¡Œåˆ‡å‰²
                    # ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ç²¾ç¡®åˆ‡å‰²å†…å®¹ï¼ˆä»åé¢åˆ‡ï¼‰
                    # å…ˆåè½¬å†…å®¹ï¼Œåˆ‡å‰²ï¼Œå†åè½¬å›æ¥
                    reversed_content = content[::-1]
                    truncated_reversed = self._binary_search_truncate(reversed_content, remaining_tokens)
                    truncated_content_only = truncated_reversed[::-1]
                    
                    # åˆ›å»ºåˆ‡å‰²åçš„æ¶ˆæ¯ï¼ˆå–åé¢éƒ¨åˆ†ï¼‰
                    truncated_msg = msg.copy()
                    truncated_content = "[...å‰é¢å†…å®¹å·²çœç•¥...]\n\n" + truncated_content_only
                    
                    # æ›´æ–°æ¶ˆæ¯å†…å®¹
                    if 'message' in truncated_msg and 'content' in truncated_msg['message']:
                        if isinstance(truncated_msg['message']['content'], list):
                            for item in truncated_msg['message']['content']:
                                if item.get('type') == 'text':
                                    item['text'] = truncated_content
                                    break
                        else:
                            truncated_msg['message']['content'] = truncated_content
                    
                    temp_back.append(truncated_msg)
                    # è®¡ç®—å®é™…æ·»åŠ çš„tokensï¼ˆè€Œä¸æ˜¯å‡è®¾å€¼ï¼‰
                    actual_truncated_tokens = self.count_tokens(truncated_content)
                    back_token_count += actual_truncated_tokens
                break  # è¾¾åˆ°ç›®æ ‡ï¼Œåœæ­¢
        
        # åè½¬back_messagesæ¢å¤åŸå§‹é¡ºåº
        back_messages = list(reversed(temp_back))
        
        # åˆå¹¶æ¶ˆæ¯ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
        extracted = []
        for msg, _, _ in message_tokens:
            if msg in front_messages or msg in back_messages:
                extracted.append(msg)
        
        # è®¡ç®—å®é™…æå–çš„tokens
        actual_tokens = 0
        for msg in extracted:
            content = self._get_message_content(msg)
            if content:
                actual_tokens += self.count_tokens(content)
        
        # ä¸éœ€è¦é¢å¤–è¡¥å……ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»ç²¾ç¡®åˆ‡å‰²åˆ°ç›®æ ‡å€¼
        
        stats['extracted_messages'] = len(extracted)
        stats['extracted_tokens'] = actual_tokens
        
        if stats['total_tokens'] > 0:
            stats['compression_ratio'] = 1 - (stats['extracted_tokens'] / stats['total_tokens'])
        
        return extracted, stats
    
    def _get_message_content(self, msg: Dict) -> str:
        """æå–æ¶ˆæ¯å†…å®¹ - åŒ¹é…Claude Codeå®é™…contextè®¡ç®—
        
        åŒ…å«æ‰€æœ‰ä¼šè¢«Claudeè®¡å…¥contextçš„å†…å®¹ï¼š
        - ç”¨æˆ·/åŠ©æ‰‹çš„æ–‡æœ¬æ¶ˆæ¯
        - æ€è€ƒå†…å®¹(thinking)
        - å·¥å…·è°ƒç”¨çš„è¾“å…¥å‚æ•°
        - å·¥å…·ç»“æœï¼ˆå¯èƒ½å¾ˆå¤§ï¼‰
        """
        texts = []
        
        def extract_all(obj, depth=0):
            """é€’å½’æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹"""
            if depth > 10:  # é˜²æ­¢æ— é™é€’å½’
                return
            
            if isinstance(obj, dict):
                # å¤„ç†messageå­—æ®µ
                if 'message' in obj and isinstance(obj['message'], dict):
                    extract_all(obj['message'], depth + 1)
                    return
                
                # å¤„ç†contentå­—æ®µ
                if 'content' in obj:
                    content = obj['content']
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict):
                                # æ–‡æœ¬å†…å®¹
                                if item.get('type') == 'text':
                                    text = item.get('text', '')
                                    if text:
                                        texts.append(text)
                                # æ€è€ƒå†…å®¹ - Claudeä¼šè®¡å…¥context
                                elif item.get('type') == 'thinking':
                                    thinking = item.get('thinking', '')
                                    if thinking:
                                        texts.append(f"[Thinking] {thinking}")
                                    # åŒæ—¶æå–signatureå­—æ®µï¼ˆthinkingçš„ç­¾åï¼‰
                                    signature = item.get('signature', '')
                                    if signature:
                                        texts.append(f"[Signature] {signature}")
                                # å·¥å…·ä½¿ç”¨ - ä½¿ç”¨å‡€åŒ–å™¨é¿å…JSONæ±¡æŸ“
                                elif item.get('type') == 'tool_use':
                                    tool_name = item.get('name', 'unknown')
                                    tool_input = item.get('input', {})
                                    # ä½¿ç”¨å‡€åŒ–å™¨è½¬æ¢ï¼Œé¿å…JSONæ ¼å¼æ±¡æŸ“ä¸Šä¸‹æ–‡
                                    sanitized = sanitize_tool_call(tool_name, tool_input)
                                    texts.append(sanitized)
                                # å·¥å…·ç»“æœ - ä½¿ç”¨å‡€åŒ–å™¨ç®€åŒ–ï¼Œé¿å…è¿‡é•¿å†…å®¹
                                elif item.get('type') == 'tool_result':
                                    result_content = item.get('content', '')
                                    if isinstance(result_content, list):
                                        # å¤šä¸ªç»“æœï¼Œç®€åŒ–è¡¨ç¤º
                                        texts.append(f"[Tool results: {len(result_content)} items]")
                                    elif result_content:
                                        # ä½¿ç”¨å‡€åŒ–å™¨ç®€åŒ–ç»“æœ
                                        sanitized_result = sanitize_tool_result(str(result_content))
                                        texts.append(sanitized_result)
                            elif isinstance(item, str):
                                texts.append(item)
                    elif isinstance(content, str) and content:
                        texts.append(content)
                
                # ç›´æ¥çš„textå­—æ®µ
                elif 'text' in obj and isinstance(obj['text'], str):
                    texts.append(obj['text'])
                # ç›´æ¥çš„thinkingå­—æ®µ
                elif 'thinking' in obj and isinstance(obj['thinking'], str):
                    texts.append(f"[Thinking] {obj['thinking']}")
        
        extract_all(msg)
        return '\n'.join(texts)
    
    def create_context_summary(self, messages: List[Dict], stats: Dict) -> str:
        """åˆ›å»ºä¸Šä¸‹æ–‡æ‘˜è¦"""
        summary = f"""# æå–çš„å¯¹è¯ä¸Šä¸‹æ–‡
_å…±{stats['extracted_messages']}æ¡æ¶ˆæ¯ï¼Œå‹ç¼©ç‡{stats['compression_ratio']:.1%}_

---

"""
        
        for msg in messages:
            content = self._get_message_content(msg)
            if content:
                # åˆ¤æ–­è§’è‰²
                role = "ğŸ‘¤ ç”¨æˆ·"
                if 'type' in msg:
                    if msg['type'] == 'assistant' or msg['type'] == 'tool_use':
                        role = "ğŸ¤– Claude"
                elif 'message' in msg and 'role' in msg['message']:
                    if msg['message']['role'] == 'assistant':
                        role = "ğŸ¤– Claude"
                
                # ä¸å†æˆªæ–­å†…å®¹ï¼Œä¿ç•™å®Œæ•´æ¶ˆæ¯
                # å¦‚æœéœ€è¦æ§åˆ¶æ€»é•¿åº¦ï¼Œåº”è¯¥åœ¨é€‰æ‹©æ¶ˆæ¯æ—¶å°±å¤„ç†ï¼Œè€Œä¸æ˜¯åœ¨è¾“å‡ºæ—¶æˆªæ–­
                
                summary += f"**{role}**: {content}\n\n"
        
        summary += f"""---

_ä½¿ç”¨{self.encoding_name}ç¼–ç å™¨ï¼Œæå–äº†{stats['extracted_tokens']}ä¸ªtoken_"""
        
        return summary
    
    def get_preview(self, messages: List[Dict], preview_lines: int = 3) -> Dict:
        """è·å–æ¶ˆæ¯é¢„è§ˆï¼ˆå¼€å¤´å’Œç»“å°¾ï¼‰"""
        preview = {
            'total_messages': len(messages),
            'head': [],
            'tail': [],
            'head_text': '',
            'tail_text': ''
        }
        
        if not messages:
            return preview
        
        # è·å–å¼€å¤´æ¶ˆæ¯
        for i, msg in enumerate(messages[:preview_lines]):
            content = self._get_message_content(msg)
            if content:
                # åˆ¤æ–­è§’è‰²
                role = "ğŸ‘¤ ç”¨æˆ·"
                if 'type' in msg:
                    if msg['type'] == 'assistant' or msg['type'] == 'tool_use':
                        role = "ğŸ¤– Claude"
                elif 'message' in msg and 'role' in msg['message']:
                    if msg['message']['role'] == 'assistant':
                        role = "ğŸ¤– Claude"
                
                # æˆªæ–­è¿‡é•¿å†…å®¹ç”¨äºé¢„è§ˆ
                if len(content) > 200:
                    content = content[:200] + "..."
                
                preview['head'].append({
                    'index': i + 1,
                    'role': role,
                    'content': content
                })
        
        # è·å–ç»“å°¾æ¶ˆæ¯
        tail_start = max(preview_lines, len(messages) - preview_lines)
        for i, msg in enumerate(messages[tail_start:], start=tail_start):
            content = self._get_message_content(msg)
            if content:
                # åˆ¤æ–­è§’è‰²
                role = "ğŸ‘¤ ç”¨æˆ·"
                if 'type' in msg:
                    if msg['type'] == 'assistant' or msg['type'] == 'tool_use':
                        role = "ğŸ¤– Claude"
                elif 'message' in msg and 'role' in msg['message']:
                    if msg['message']['role'] == 'assistant':
                        role = "ğŸ¤– Claude"
                
                # æˆªæ–­è¿‡é•¿å†…å®¹ç”¨äºé¢„è§ˆ
                if len(content) > 200:
                    content = content[:200] + "..."
                
                preview['tail'].append({
                    'index': i + 1,
                    'role': role,
                    'content': content
                })
        
        # ç”Ÿæˆé¢„è§ˆæ–‡æœ¬
        head_lines = []
        for item in preview['head']:
            head_lines.append(f"  [{item['index']:3d}] {item['role']}: {item['content']}")
        preview['head_text'] = '\n'.join(head_lines)
        
        tail_lines = []
        for item in preview['tail']:
            tail_lines.append(f"  [{item['index']:3d}] {item['role']}: {item['content']}")
        preview['tail_text'] = '\n'.join(tail_lines)
        
        return preview

def process_session_worker(args):
    """å¤šè¿›ç¨‹workerå‡½æ•° - å¤„ç†å•ä¸ªä¼šè¯"""
    idx, session_path = args
    try:
        # åˆ›å»ºæ–°çš„extractorå®ä¾‹ï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹ï¼‰
        extractor = ClaudeContextExtractor()
        info = extractor.get_session_info(session_path)
        info['needs_full_load'] = False
        return idx, info
    except Exception as e:
        # å‡ºé”™æ—¶è¿”å›é»˜è®¤å€¼
        info = {
            'path': session_path,
            'name': session_path.name,
            'size': session_path.stat().st_size,
            'mtime': session_path.stat().st_mtime,
            'message_count': 0,
            'meaningful_messages': [],
            'last_messages': [],
            'tokens': 0,
            'topics': [],
            'summaries': [],
            'git_branch': None,
            'duration': None,
            'project_dir': session_path.parent.name,
            'needs_full_load': True,
            'error': str(e)[:100]
        }
        return idx, info

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Claudeå¯¹è¯ä¸Šä¸‹æ–‡æ™ºèƒ½æå–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # ç®€åŒ–ï¼šé»˜è®¤å°±æ˜¯äº¤äº’æ¨¡å¼
    parser.add_argument(
        '--tokens', '-t',
        type=int,
        default=100000,
        help='æœ€å¤§tokenæ•°é‡ï¼ˆé»˜è®¤100000ï¼‰'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è¾“å‡ºåˆ°ç»ˆç«¯ï¼‰'
    )
    
    parser.add_argument(
        '--send',
        action='store_true',
        help='ç›´æ¥å‘é€åˆ°Claude CLI'
    )
    
    parser.add_argument(
        '--stats',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæå–å™¨
    extractor = ClaudeContextExtractor(max_tokens=args.tokens)
    
    # æ˜¾ç¤ºç¼–ç å™¨ä¿¡æ¯
    if args.stats:
        print(f"ğŸ”§ ç¼–ç å™¨: {extractor.encoding_name}", file=sys.stderr)
        if not TIKTOKEN_AVAILABLE:
            print("âš   tiktokenæœªå®‰è£…ï¼Œä½¿ç”¨ä¼°ç®—æ¨¡å¼", file=sys.stderr)
    
    # æŸ¥æ‰¾ä¼šè¯
    sessions = extractor.find_claude_sessions()
    
    if not sessions:
        print("âŒ æœªæ‰¾åˆ°Claudeä¼šè¯æ–‡ä»¶", file=sys.stderr)
        sys.exit(1)
    
    # é»˜è®¤è¿›å…¥äº¤äº’å¼é€‰æ‹©ï¼ˆç®€åŒ–æµç¨‹ï¼‰
    if True:  # æ€»æ˜¯ä½¿ç”¨äº¤äº’æ¨¡å¼
        # ä½¿ç”¨æ–°çš„åˆ†é¡µUI
        from .interactive_ui import InteractiveSessionSelector
        
        # é¢„åŠ è½½ä¼šè¯ä¿¡æ¯ï¼ˆåªåŠ è½½ç¬¬ä¸€é¡µï¼‰
        print("â³ æ­£åœ¨åŠ è½½ä¼šè¯åˆ—è¡¨...", file=sys.stderr)
        session_infos = []
        page_size = 3  # ä¸UIçš„page_sizeåŒ¹é…
        
        # åªè·å–åŸºæœ¬ä¿¡æ¯ï¼Œä¸è®¡ç®—tokensï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        for session in sessions:
            # å¿«é€Ÿè·å–åŸºæœ¬ä¿¡æ¯
            info = {
                'path': session,
                'name': session.name,
                'size': session.stat().st_size,
                'mtime': session.stat().st_mtime,
                'message_count': 0,  # å»¶è¿ŸåŠ è½½
                'meaningful_messages': [],
                'last_messages': [],
                'tokens': 0,  # å»¶è¿ŸåŠ è½½
                'topics': [],
                'summaries': [],
                'git_branch': None,
                'duration': None,
                'project_dir': session.parent.name,
                'needs_full_load': True  # æ ‡è®°éœ€è¦åŠ è½½
            }
            session_infos.append(info)
        
        # åªè®¡ç®—ç¬¬ä¸€é¡µçš„ä¼šè¯ï¼ˆå‰3ä¸ªï¼‰
        print(f"  è®¡ç®—å‰ {page_size} ä¸ªä¼šè¯...", file=sys.stderr)
        for i in range(min(page_size, len(session_infos))):
            try:
                full_info = extractor.get_session_info(session_infos[i]['path'])
                full_info['needs_full_load'] = False
                session_infos[i] = full_info
            except Exception as e:
                print(f"  âš  åŠ è½½ä¼šè¯ {i+1} å¤±è´¥: {e}", file=sys.stderr)
        
        # åˆ›å»ºå¹¶è¿è¡Œé€‰æ‹©å™¨ï¼ˆä¼ å…¥extractorç”¨äºå»¶è¿ŸåŠ è½½ï¼‰
        selector = InteractiveSessionSelector(session_infos, page_size=3, extractor=extractor)
        selected_info = selector.run()
        
        if not selected_info:
            sys.exit(0)
        
        selected = selected_info['path']
        
        # å¦‚æœé€‰ä¸­çš„ä¼šè¯è¿˜æ²¡æœ‰å®Œæ•´åŠ è½½ï¼Œç°åœ¨åŠ è½½
        if selected_info.get('needs_full_load') or selected_info['message_count'] == 0:
            print("â³ æ­£åœ¨åˆ†æé€‰ä¸­çš„ä¼šè¯...", file=sys.stderr)
            full_info = extractor.get_session_info(selected)
            selected_info.update(full_info)
        
        # æ˜¾ç¤ºè¯¦ç»†çš„ç¡®è®¤ä¿¡æ¯
        
        # Avoid ANSI clear-screen sequences to prevent rendering issues on iOS Termius
        # Previously used: print("\033[2J\033[H", end='', file=sys.stderr)
        print("ğŸ“‹ ä¼šè¯è¯¦æƒ…", file=sys.stderr)
        print("=" * 60, file=sys.stderr)
        
        # æ˜¾ç¤ºä¼šè¯åŸºæœ¬ä¿¡æ¯
        from datetime import datetime
        mtime = datetime.fromtimestamp(selected_info['mtime'])
        print(f"\nâ° æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}", file=sys.stderr)
        print(f"ğŸ“Š ç»Ÿè®¡: {selected_info['message_count']} æ¡æ¶ˆæ¯", file=sys.stderr)
        print(f"ğŸ’¾ å¤§å°: â‰ˆ{selected_info['tokens']:,} tokens(ä¼°ç®—)", file=sys.stderr)
        
        if selected_info.get('summaries'):
            summary = selected_info['summaries'][0]
            if len(summary) > 70:
                summary = summary[:67] + "..."
            print(f"ğŸ“Œ ä¸»é¢˜: {summary}", file=sys.stderr)
        
        if selected_info.get('git_branch'):
            print(f"ğŸŒ¿ åˆ†æ”¯: {selected_info['git_branch']}", file=sys.stderr)
        
        # æ˜¾ç¤ºæ›´è¯¦ç»†çš„å¯¹è¯å†…å®¹
        print(f"\nğŸ’¬ å¯¹è¯é¢„è§ˆ:", file=sys.stderr)
        print("=" * 60, file=sys.stderr)
        
        # æ˜¾ç¤ºå‰5æ¡æœ‰æ„ä¹‰çš„æ¶ˆæ¯
        if selected_info.get('meaningful_messages'):
            print("\nğŸ”¸ å¼€å§‹å¯¹è¯:", file=sys.stderr)
            for i, msg in enumerate(selected_info['meaningful_messages'][:5], 1):
                # æ¸…ç†å·¥å…·è°ƒç”¨
                if '[Tool' not in msg and '[Thinking]' not in msg:
                    if msg.startswith('ğŸ‘¤') or msg.startswith('ğŸ¤–'):
                        print(f"  {i}. {msg[:100]}", file=sys.stderr)
                    else:
                        print(f"  {i}. {msg[:100]}", file=sys.stderr)
        
        # æ˜¾ç¤ºæœ€å5æ¡æ¶ˆæ¯
        if selected_info.get('last_messages'):
            print("\nğŸ”š æœ€è¿‘å¯¹è¯:", file=sys.stderr)
            for i, msg in enumerate(selected_info['last_messages'][:5], 1):
                if '[Tool' not in msg and '[Thinking]' not in msg:
                    if msg.startswith('ğŸ‘¤') or msg.startswith('ğŸ¤–'):
                        print(f"  {i}. {msg[:100]}", file=sys.stderr)
                    else:
                        print(f"  {i}. {msg[:100]}", file=sys.stderr)
        
        # æ˜¾ç¤ºå¯é€‰æ“ä½œ
        print("\n" + "=" * 60, file=sys.stderr)
        print("\nğŸ¯ å¯é€‰æ“ä½œ:", file=sys.stderr)
        print("=" * 60, file=sys.stderr)
        
        # ç‰¹æ®Šå¤„ç†ç©ºä¼šè¯
        if selected_info['tokens'] == 0 or selected_info['message_count'] <= 2:
            print("âš   è¿™æ˜¯ä¸€ä¸ªç©ºä¼šè¯ï¼ˆæ— å®é™…å¯¹è¯å†…å®¹ï¼‰", file=sys.stderr)
            print("\n  [D] åˆ é™¤æ­¤ç©ºä¼šè¯ (Delete)", file=sys.stderr)
            print("  [B] è¿”å›åˆ—è¡¨ (Back)", file=sys.stderr)
            print("  [Q] é€€å‡º (Quit)", file=sys.stderr)
        elif selected_info['tokens'] < 100000:
            print(f"âœ… ä¼šè¯è¾ƒå° (â‰ˆ{selected_info['tokens']:,} tokens < 100k)", file=sys.stderr)
            print("\n  [R] ç›´æ¥æ¢å¤ (Resume) - ä¿ç•™100%åŸå§‹ä¸Šä¸‹æ–‡", file=sys.stderr)
            print("      âš¡ é»˜è®¤å¯ç”¨ --dangerously-skip-permissions", file=sys.stderr)
            print("  [C] æ™ºèƒ½å‹ç¼© (Compress) - å°ä¼šè¯å°†ç›´æ¥æ¢å¤", file=sys.stderr)
            print("  [B] è¿”å›åˆ—è¡¨ (Back)", file=sys.stderr)
            print("  [Q] é€€å‡º (Quit)", file=sys.stderr)
        else:
            print(f"ğŸ“Š ä¼šè¯å¤§å°: â‰ˆ{selected_info['tokens']:,} tokens(ä¼°ç®—)", file=sys.stderr)
            print("\n  [R] ç›´æ¥æ¢å¤ (Resume) - ä¿ç•™100%åŸå§‹ä¸Šä¸‹æ–‡", file=sys.stderr)
            if selected_info['tokens'] > 200000:
                print(f"      âš   è­¦å‘Š: ä¼šè¯è¶…è¿‡200ké™åˆ¶ï¼Œå¯èƒ½æ— æ³•å®Œå…¨åŠ è½½", file=sys.stderr)
            print("      âš¡ é»˜è®¤å¯ç”¨ --dangerously-skip-permissions", file=sys.stderr)
            print("  [C] æ™ºèƒ½å‹ç¼© (Compress) - æå–å…³é”®ä¿¡æ¯", file=sys.stderr)
            print("      é¢„è®¡å‹ç¼©å: â‰ˆ100,000 tokens(ä¼°ç®—)", file=sys.stderr)
            print("      (ä¿ç•™å‰â‰ˆ25k + åâ‰ˆ75k tokens)", file=sys.stderr)
            print("  [B] è¿”å›åˆ—è¡¨ (Back)", file=sys.stderr)
            print("  [Q] é€€å‡º (Quit)", file=sys.stderr)
        
        
        # è¯¢é—®ç”¨æˆ·é€‰æ‹©
        print("\n" + "=" * 60, file=sys.stderr)
        
        # æ ¹æ®ä¼šè¯ç±»å‹è°ƒæ•´æç¤º
        if selected_info['tokens'] == 0 or selected_info['message_count'] <= 2:
            prompt = "\nè¯·é€‰æ‹©æ“ä½œ [D/B/Q]: "
        else:
            prompt = "\nè¯·é€‰æ‹©æ“ä½œ [R/C/B/Q]: "
        
        while True:
            try:
                choice = input(prompt).strip().lower()
                
                if choice == 'q':
                    print("\nğŸ‘‹ å·²é€€å‡º", file=sys.stderr)
                    sys.exit(0)
                    
                elif choice == 'b':
                    # è¿”å›ä¼šè¯é€‰æ‹©ï¼ˆé‡æ–°è¿è¡Œä¸»å‡½æ•°ï¼‰
                    print("\nğŸ”„ è¿”å›ä¼šè¯åˆ—è¡¨...", file=sys.stderr)
                    # é‡æ–°è°ƒç”¨mainå‡½æ•°
                    sys.argv = ['ccdrc']
                    main()
                    return
                    
                elif choice == 'r':
                    # ç›´æ¥æ¢å¤ï¼ˆå¯¹æ‰€æœ‰å¤§å°çš„ä¼šè¯éƒ½å…è®¸ï¼‰
                    session_id = selected.stem
                    print(f"\nğŸš€ æ­£åœ¨ä½¿ç”¨ --resume æ¢å¤ä¼šè¯...", file=sys.stderr)
                    if selected_info['tokens'] > 200000:
                        print(f"âš   è­¦å‘Š: ä¼šè¯åŒ…å« â‰ˆ{selected_info['tokens']:,} tokens(ä¼°ç®—)ï¼Œè¶…è¿‡Claudeçš„200ké™åˆ¶", file=sys.stderr)
                        print("   ç»§ç»­æ¢å¤å¯èƒ½ä¼šå› ä¸ºè¶…å‡ºé™åˆ¶è€Œå¤±è´¥", file=sys.stderr)
                    print(f"âš¡ å·²å¯ç”¨ --dangerously-skip-permissions è·³è¿‡æƒé™æ£€æŸ¥", file=sys.stderr)
                    
                    # FIX: ä½¿ç”¨os.systemä¿æŒç»ˆç«¯çŠ¶æ€ï¼Œç¡®ä¿tokenæ˜¾ç¤º
                    import os
                    # å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒº
                    sys.stdout.flush()
                    sys.stderr.flush()
                    # æ·»åŠ --verboseç¡®ä¿tokenæ˜¾ç¤º
                    cmd = f'claude --resume {session_id} --verbose --dangerously-skip-permissions'
                    exit_code = os.system(cmd)
                    sys.exit(exit_code >> 8)
                        
                elif choice == 'd' and (selected_info['tokens'] == 0 or selected_info['message_count'] <= 2):
                    # åˆ é™¤ç©ºä¼šè¯
                    print(f"\nğŸ—‘  æ­£åœ¨åˆ é™¤ç©ºä¼šè¯...", file=sys.stderr)
                    try:
                        selected.unlink()  # åˆ é™¤æ–‡ä»¶
                        print("âœ… ç©ºä¼šè¯å·²åˆ é™¤", file=sys.stderr)
                        print("\nğŸ”„ è¿”å›ä¼šè¯åˆ—è¡¨...", file=sys.stderr)
                        sys.argv = ['ccdrc']
                        main()
                        return
                    except Exception as e:
                        print(f"âŒ åˆ é™¤å¤±è´¥: {e}", file=sys.stderr)
                        
                elif choice == 'c' and selected_info['tokens'] > 0:
                    # ç”¨æˆ·é€‰æ‹©å‹ç¼©
                    if selected_info['tokens'] < 100000:
                        # <100kï¼Œç›´æ¥æ¢å¤ï¼ˆå‹ç¼©åç»“æœä¸€æ ·ï¼‰
                        session_id = selected.stem
                        print(f"\nâœ¨ ä¼šè¯è¾ƒå°ï¼ˆâ‰ˆ{selected_info['tokens']:,} tokens(ä¼°) < 100kï¼‰ï¼Œç›´æ¥æ¢å¤", file=sys.stderr)
                        print(f"   ï¼ˆå°ä¼šè¯å‹ç¼©å’Œæ¢å¤æ•ˆæœç›¸åŒï¼‰", file=sys.stderr)
                        print(f"âš¡ å·²å¯ç”¨ --dangerously-skip-permissions è·³è¿‡æƒé™æ£€æŸ¥", file=sys.stderr)
                        
                        # FIX: ä½¿ç”¨os.systemä¿æŒç»ˆç«¯çŠ¶æ€ï¼Œç¡®ä¿tokenæ˜¾ç¤º
                        import os
                        # å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒº
                        sys.stdout.flush()
                        sys.stderr.flush()
                        # æ·»åŠ --verboseç¡®ä¿tokenæ˜¾ç¤º
                        cmd = f'claude --resume {session_id} --verbose --dangerously-skip-permissions'
                        exit_code = os.system(cmd)
                        sys.exit(exit_code >> 8)
                    else:
                        # >=100kï¼Œè¿›è¡Œå‹ç¼©
                        print(f"\nğŸ—ƒ  æ­£åœ¨è¿›è¡Œæ™ºèƒ½å‹ç¼©...", file=sys.stderr)
                        # äº¤äº’æ¨¡å¼ä¸‹ï¼Œå‹ç¼©åè‡ªåŠ¨å‘é€ç»™Claude
                        args.send = True
                        break  # ç»§ç»­æ‰§è¡Œåç»­çš„å‹ç¼©é€»è¾‘
                    
                else:
                    if selected_info['tokens'] == 0 or selected_info['message_count'] <= 2:
                        print("âš   æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ D/B/Q", file=sys.stderr)
                    else:
                        print("âš   æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ R/C/B/Q", file=sys.stderr)
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å·²é€€å‡º", file=sys.stderr)
                sys.exit(0)
    
    # è§£æä¼šè¯ï¼ˆç”¨æˆ·å·²ç»åœ¨äº¤äº’ç•Œé¢é€‰æ‹©äº†å‹ç¼©ï¼Œä¸”tokens>=100kï¼‰
    if args.stats:
        print(f"\nğŸ“– è§£æä¼šè¯: {selected.name}", file=sys.stderr)
    
    messages = extractor.parse_session(selected)
    
    if not messages:
        print("âŒ ä¼šè¯æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯", file=sys.stderr)
        sys.exit(1)
    
    # è·å–tokenæ•°ç”¨äºæ˜¾ç¤º
    total_tokens = selected_info.get('tokens', 0)
    
    # æ‰§è¡Œåˆ°è¿™é‡Œè¯´æ˜ç”¨æˆ·é€‰æ‹©äº†Cä¸”tokens>=100kï¼Œç›´æ¥è¿›è¡Œå‹ç¼©
    print(f"\nâš   æ­£åœ¨å‹ç¼©ä¼šè¯ï¼ˆâ‰ˆ{total_tokens:,} tokensä¼°ç®—ï¼‰", file=sys.stderr)
    
    # æå–å…³é”®æ¶ˆæ¯
    extracted, stats = extractor.extract_key_messages(messages)
    
    # æ˜¾ç¤ºç»Ÿè®¡ï¼ˆäº¤äº’æ¨¡å¼ä¸‹æ€»æ˜¯æ˜¾ç¤ºï¼‰
    print(f"\nğŸ“Š å‹ç¼©ç»Ÿè®¡:", file=sys.stderr)
    print(f"  åŸå§‹: {stats['total_messages']}æ¡æ¶ˆæ¯, â‰ˆ{stats['total_tokens']:,} tokens(ä¼°)", file=sys.stderr)
    print(f"  å‹ç¼©å: {stats['extracted_messages']}æ¡æ¶ˆæ¯, â‰ˆ{stats['extracted_tokens']:,} tokens(ä¼°)", file=sys.stderr)
    print(f"  å‹ç¼©ç‡: {stats['compression_ratio']:.1%}", file=sys.stderr)
    print(f"  ä½¿ç”¨{extractor.encoder.name}ç¼–ç å™¨ï¼Œæå–äº†â‰ˆ{stats['extracted_tokens']}ä¸ªtoken(ä¼°ç®—)", file=sys.stderr)
    
    # å‘é€åˆ°Claudeæ—¶éœ€è¦ç¡®è®¤ï¼ˆä½†äº¤äº’æ¨¡å¼é€‰æ‹©åä¸éœ€è¦ï¼‰
    # ç°åœ¨æ€»æ˜¯äº¤äº’æ¨¡å¼ï¼Œæ‰€ä»¥ä¸éœ€è¦å†æ¬¡ç¡®è®¤
    need_confirm = False
    
    if need_confirm:
        # è·å–é¢„è§ˆ
        preview = extractor.get_preview(extracted, preview_lines=3)
        
        # æ˜¾ç¤ºé¢„è§ˆä¿¡æ¯
        print("\n" + "=" * 60, file=sys.stderr)
        print("ğŸ“‹ ä¼šè¯é¢„è§ˆ", file=sys.stderr)
        print("=" * 60, file=sys.stderr)
        print(f"\nğŸ“Š ç»Ÿè®¡:", file=sys.stderr)
        print(f"  â€¢ ä¼šè¯æ–‡ä»¶: {selected.name}", file=sys.stderr)
        print(f"  â€¢ æ¶ˆæ¯æ€»æ•°: {stats['extracted_messages']} æ¡", file=sys.stderr)
        print(f"  â€¢ Tokenæ€»æ•°: {stats['extracted_tokens']} tokens", file=sys.stderr)
        print(f"  â€¢ å‹ç¼©ç‡: {stats['compression_ratio']:.1%}", file=sys.stderr)
        
        print(f"\nğŸ“ å¼€å¤´å†…å®¹ï¼ˆå‰{len(preview['head'])}æ¡ï¼‰:", file=sys.stderr)
        print(preview['head_text'], file=sys.stderr)
        
        if preview['total_messages'] > 6:
            print(f"\n  ... çœç•¥ {preview['total_messages'] - 6} æ¡æ¶ˆæ¯ ...", file=sys.stderr)
        
        print(f"\nğŸ“ ç»“å°¾å†…å®¹ï¼ˆå{len(preview['tail'])}æ¡ï¼‰:", file=sys.stderr)
        print(preview['tail_text'], file=sys.stderr)
        
        print("\n" + "=" * 60, file=sys.stderr)
        
        # è¯¢é—®ç”¨æˆ·ç¡®è®¤
        while True:
            print("\nâ“ æ˜¯å¦å‘é€åˆ°Claudeï¼Ÿ", file=sys.stderr)
            print("  [Y] æ˜¯ï¼Œå‘é€", file=sys.stderr)
            print("  [N] å¦ï¼Œå–æ¶ˆ", file=sys.stderr)
            print("  [R] é‡æ–°é€‰æ‹©ä¼šè¯", file=sys.stderr)
            
            try:
                choice = input("è¯·é€‰æ‹© (Y/n/r): ").strip().lower()
                if choice == '' or choice == 'y':
                    # ç»§ç»­å‘é€
                    break
                elif choice == 'n':
                    print("\nâŒ å·²å–æ¶ˆ", file=sys.stderr)
                    sys.exit(0)
                elif choice == 'r':
                    # é‡æ–°é€‰æ‹©ä¼šè¯
                    print("\nğŸ”„ é‡æ–°é€‰æ‹©ä¼šè¯...", file=sys.stderr)
                    # é€’å½’è°ƒç”¨mainï¼ˆå®é™…ä¸Šåº”è¯¥é‡æ„ä¸ºå¾ªç¯ï¼‰
                    sys.argv = ['ccdrc-extract']
                    if args.send:
                        sys.argv.append('--send')
                    if args.stats:
                        sys.argv.append('--stats')
                    main()
                    return
                else:
                    print("âš   è¯·è¾“å…¥ Yã€N æˆ– R", file=sys.stderr)
            except KeyboardInterrupt:
                print("\n\nâŒ å·²å–æ¶ˆ", file=sys.stderr)
                sys.exit(0)
    
    # åˆ›å»ºæ‘˜è¦
    summary = extractor.create_context_summary(extracted, stats)
    
    # è¾“å‡ºç»“æœ
    if args.output:
        if args.output == '/dev/stdout':
            print(summary)
        else:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(summary)
            print(f"âœ… å·²ä¿å­˜åˆ°: {args.output}", file=sys.stderr)
    elif args.send:
        # é€šè¿‡ç®¡é“å‘é€åˆ°Claude
        # FIX: ä½¿ç”¨os.systemå’Œä¸´æ—¶æ–‡ä»¶ä¿æŒç»ˆç«¯çŠ¶æ€
        import os
        import tempfile
        print("\nğŸš€ æ­£åœ¨å¯åŠ¨Claude...\n", file=sys.stderr)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å­˜å‚¨å†…å®¹
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as tf:
            tf.write(summary)
            temp_path = tf.name
        
        try:
            # ä½¿ç”¨os.systemç¡®ä¿ç»ˆç«¯çŠ¶æ€æ­£ç¡®ä¼ é€’ï¼Œæ·»åŠ --verboseç¡®ä¿tokenæ˜¾ç¤º
            exit_code = os.system(f'cat "{temp_path}" | claude --verbose --dangerously-skip-permissions')
            exit_code = exit_code >> 8  # è·å–å®é™…é€€å‡ºç 
            
            # Claudeå·²ç»é€€å‡ºï¼Œæ ¹æ®è¿”å›ç åˆ¤æ–­
            if exit_code == 0:
                print("\nâœ… Claudeä¼šè¯å·²ç»“æŸ", file=sys.stderr)
            else:
                print(f"\nâš   Claudeé€€å‡ºä»£ç : {exit_code}", file=sys.stderr)
        finally:
            os.unlink(temp_path)
    else:
        print(summary)

if __name__ == '__main__':
    main()