#!/usr/bin/env python3
"""
ä¿®å¤tokenè®¡ç®—ç®—æ³•
åŸºäºå®é™…æµ‹é‡ï¼š139kå®é™… vs 43.8kæ˜¾ç¤º
"""

import json
from pathlib import Path

def calculate_realistic_tokens(session_path):
    """æ›´å‡†ç¡®çš„tokenè®¡ç®—æ–¹æ³•"""
    
    # è¯»å–ä¼šè¯æ–‡ä»¶
    messages = []
    with open(session_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    messages.append(json.loads(line))
                except:
                    pass
    
    # æ–¹æ³•1ï¼šåŸºäºæ–‡ä»¶å¤§å°çš„ç»éªŒå…¬å¼
    # å®æµ‹ï¼š1.8MBæ–‡ä»¶ â‰ˆ 139k tokens
    # æ¯”ä¾‹ï¼š1KB â‰ˆ 76 tokens
    file_size_kb = session_path.stat().st_size / 1024
    size_based_estimate = int(file_size_kb * 76)
    
    # æ–¹æ³•2ï¼šåŸºäºæ¶ˆæ¯æ•°é‡çš„ç»éªŒå…¬å¼
    # 692æ¡æ¶ˆæ¯ â‰ˆ 139k tokens
    # å¹³å‡æ¯æ¡æ¶ˆæ¯ â‰ˆ 200 tokens
    message_based_estimate = len(messages) * 200
    
    # æ–¹æ³•3ï¼šæ··åˆè®¡ç®—ï¼ˆæ›´å‡†ç¡®ï¼‰
    # è€ƒè™‘æ–‡æœ¬å†…å®¹ + JSONç»“æ„å¼€é”€
    text_chars = 0
    for msg in messages:
        # é€’å½’æå–æ‰€æœ‰æ–‡æœ¬
        def extract_text(obj):
            if isinstance(obj, str):
                return len(obj)
            elif isinstance(obj, dict):
                return sum(extract_text(v) for v in obj.values())
            elif isinstance(obj, list):
                return sum(extract_text(item) for item in obj)
            return 0
        
        text_chars += extract_text(msg)
    
    # æ–‡æœ¬tokensï¼ˆè‹±æ–‡ä¸ºä¸»çº¦4å­—ç¬¦/tokenï¼‰
    text_tokens = text_chars // 4
    
    # JSONå¼€é”€ç³»æ•°ï¼ˆåŸºäºå®æµ‹ï¼‰
    # å®é™…tokens / çº¯æ–‡æœ¬tokens â‰ˆ 5.8
    JSON_OVERHEAD_FACTOR = 5.8
    hybrid_estimate = int(text_tokens * JSON_OVERHEAD_FACTOR)
    
    print("="*60)
    print("Tokenè®¡ç®—æ–¹æ³•å¯¹æ¯”")
    print("="*60)
    
    print(f"\nğŸ“ æ–‡ä»¶: {session_path.name}")
    print(f"   å¤§å°: {file_size_kb:.1f} KB")
    print(f"   æ¶ˆæ¯æ•°: {len(messages)}")
    
    print(f"\nğŸ“Š ä¸åŒè®¡ç®—æ–¹æ³•:")
    print(f"   1. åŸºäºæ–‡ä»¶å¤§å°: {size_based_estimate:,} tokens")
    print(f"      (1KB â‰ˆ 76 tokens)")
    print(f"   2. åŸºäºæ¶ˆæ¯æ•°é‡: {message_based_estimate:,} tokens")
    print(f"      (æ¯æ¡æ¶ˆæ¯ â‰ˆ 200 tokens)")
    print(f"   3. æ··åˆè®¡ç®—: {hybrid_estimate:,} tokens")
    print(f"      (æ–‡æœ¬Ã—5.8å€ç³»æ•°)")
    
    # å–å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆä¼°ç®—
    final_estimate = (size_based_estimate + message_based_estimate + hybrid_estimate) // 3
    
    print(f"\nğŸ¯ æœ€ç»ˆä¼°ç®—: {final_estimate:,} tokens")
    print(f"   (ä¸‰ç§æ–¹æ³•çš„å¹³å‡å€¼)")
    
    return final_estimate

def patch_extractor():
    """ä¿®è¡¥CCCçš„tokenè®¡ç®—æ–¹æ³•"""
    
    patch_code = '''
# ä¿®æ­£çš„tokenè®¡ç®—æ–¹æ³•
def get_session_info(self, session_path: Path) -> Dict:
    """è·å–ä¼šè¯çš„è¯¦ç»†ä¿¡æ¯ - ä¿®æ­£ç‰ˆ"""
    info = super().get_session_info(session_path)
    
    # ä½¿ç”¨æ›´å‡†ç¡®çš„tokenè®¡ç®—
    # åŸºäºå®æµ‹ï¼šæ–‡ä»¶å¤§å°(KB) Ã— 76 â‰ˆ å®é™…tokens
    file_size_kb = session_path.stat().st_size / 1024
    realistic_tokens = int(file_size_kb * 76)
    
    # æ›¿æ¢åŸæ¥çš„ä¸å‡†ç¡®è®¡ç®—
    info['tokens'] = realistic_tokens
    
    return info
'''
    
    print("\n" + "="*60)
    print("å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ")
    print("="*60)
    print(patch_code)

if __name__ == "__main__":
    import sys
    # Removed legacy sys.path hack for ccdrc
    from ccc.extractor import ClaudeContextExtractor
    
    # æµ‹è¯•æœ€è¿‘çš„ä¼šè¯
    extractor = ClaudeContextExtractor()
    sessions = extractor.find_claude_sessions()
    
    if sessions and len(sessions) >= 3:
        session_path = sessions[2]

        # è®¡ç®—å‡†ç¡®çš„tokens
        realistic = calculate_realistic_tokens(session_path)

        # å¯¹æ¯”CCCå½“å‰çš„è®¡ç®—
        info = extractor.get_session_info(session_path)
        ccc_tokens = info['tokens']

        print("\n" + "="*60)
        print("å¯¹æ¯”ç»“æœ")
        print("="*60)
        print(f"CCCå½“å‰æ˜¾ç¤º: {ccc_tokens:,} tokens")
        print(f"ä¿®æ­£åä¼°ç®—: {realistic:,} tokens")
        print(f"æ‚¨æåˆ°çš„å®é™…: 139,000 tokens")
        print(f"å‡†ç¡®åº¦æå‡: {abs(139000 - realistic) < abs(139000 - ccc_tokens)}")

        # æ˜¾ç¤ºä¿®å¤å»ºè®®
        patch_extractor()